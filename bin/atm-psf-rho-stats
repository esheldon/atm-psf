#!/usr/bin/env python


def calc_rho_stats(
    ra, dec,
    T,
    g1, g2,
    psf_T,
    psf_g1, psf_g2,
    min_sep=0.5,
    max_sep=50,
    bin_size=0.1,
    file_name=None,
    model_properties=None,
    logger=None,
    **kwargs,
):
    import treecorr
    import galsim

    # treecorr.set_max_omp_threads(1)

    tckwargs = kwargs
    tckwargs['min_sep'] = min_sep
    tckwargs['max_sep'] = max_sep
    tckwargs['bin_size'] = bin_size

    if 'sep_units' not in tckwargs:
        tckwargs['sep_units'] = 'arcmin'

    # Set this to true if there is a problem and we need to skip plots.
    # skip = False

    logger = galsim.config.LoggerWrapper(logger)

    # get the shapes
    print(f'Calculating rho statistics for {ra.size} stars')

    dT = T - psf_T
    dg1 = g1 - psf_g1
    dg2 = g2 - psf_g2

    # make the treecorr catalogs
    logger.info("Creating Treecorr Catalogs")

    cat_g = treecorr.Catalog(
        ra=ra, dec=dec,
        ra_units='deg', dec_units='deg',
        g1=g1, g2=g2,
    )
    cat_dg = treecorr.Catalog(
        ra=ra, dec=dec,
        ra_units='deg', dec_units='deg',
        g1=dg1, g2=dg2,
    )
    cat_gdTT = treecorr.Catalog(
        ra=ra, dec=dec,
        ra_units='deg', dec_units='deg',
        g1=g1 * dT / T, g2=g2 * dT / T,
    )

    # setup and run the correlations
    logger.info("Processing rho PSF statistics")

    # save the rho objects
    data = {}
    data['rho1'] = treecorr.GGCorrelation(tckwargs)
    data['rho1'].process(cat_dg)
    data['rho2'] = treecorr.GGCorrelation(tckwargs)
    data['rho2'].process(cat_g, cat_dg)
    data['rho3'] = treecorr.GGCorrelation(tckwargs)
    data['rho3'].process(cat_gdTT)
    data['rho4'] = treecorr.GGCorrelation(tckwargs)
    data['rho4'].process(cat_dg, cat_gdTT)
    data['rho5'] = treecorr.GGCorrelation(tckwargs)
    data['rho5'].process(cat_g, cat_gdTT)
    # treecorr.set_max_omp_threads(None)

    return data


def get_flist(fname):
    flist = []
    print('reading files from:', fname)
    with open(fname) as fobj:
        for line in fobj:
            flist.append(line.strip())
    return flist


def read_one(inputs):
    import numpy as np
    import esutil as eu
    import fitsio
    import ngmix

    fname, nstar_min, seeing_min = inputs

    columns = [
        'ra', 'dec',
        'am_T', 'am_e1', 'am_e2',
        'am_psf_T', 'am_psf_e1', 'am_psf_e2',
    ]

    data = fitsio.read(fname)
    n = data['star_select'].sum()
    if 'am_flags' in data.dtype.names and n >= nstar_min:

        w, = np.where(
            data['reserved']
            # data['star_select']
            # & (~data['reserved'])
            & (data['am_flags'] == 0)
            & (data['am_psf_flags'] == 0)
        )

        data = data[w]

        seeing = np.median(ngmix.moments.T_to_fwhm(data['am_psf_T']))
        if seeing < seeing_min:
            data = None
        else:
            if 'am_flags' in data.dtype.names:
                data = eu.numpy_util.extract_fields(data, columns)
    else:
        data = None

    return data


def read_data(args):
    import esutil as eu
    from tqdm import tqdm
    import multiprocessing

    flist = get_flist(args.flist)

    ncols = 70
    mininterval = 0.5
    if args.nproc != 1:
        inputs = [
            (fname, args.nstar_min, args.seeing_min) for fname in flist
        ]
        pool = multiprocessing.Pool(args.nproc)

        dlist = []
        for data in tqdm(
            pool.imap_unordered(read_one, inputs),
            total=len(inputs),
            ascii=True,
            ncols=ncols,
            mininterval=mininterval,
        ):
            if data is not None:
                dlist.append(data)

    else:
        dlist = []
        for f in tqdm(
            flist, ncols=ncols, ascii=True, mininterval=mininterval,
        ):
            data = read_one((f, args.nstar_min, args.seeing_min))
            if data is not None:
                dlist.append(data)

    print(f'kept {len(dlist)}/{len(flist)}')
    return eu.numpy_util.combine_arrlist(dlist)


def get_args():
    import argparse

    parser = argparse.ArgumentParser()
    parser.add_argument('--flist', required=True,
                        help='file holding list of inputs')
    parser.add_argument('--front', required=True,
                        help='front for file names')

    parser.add_argument(
        '--nstar-min',
        type=int, default=50,
        help='only use images with at least this many stars, default 50'
    )
    parser.add_argument(
        '--nproc', type=int, default=1,
        help='number of processes to use, default 1'
    )

    parser.add_argument(
        '--min-sep', type=float, default=0.5,
        help='minimum separation, default 0.5 arcmin'
    )
    parser.add_argument(
        '--max-sep', type=float, default=50,
        help='maximum separation, default 50 arcmin'
    )

    parser.add_argument(
        '--seeing-min', type=float, default=0,
        help='min seeing, default 0'
    )

    return parser.parse_args()


def main():
    args = get_args()

    print('reading data')
    st = read_data(args)

    print('running treecorr')

    # note e1/e2 get factor of 1/2 to convert to reduced shear style
    if 'am_e1' in st.dtype.names:
        g1 = st['am_e1'] * 0.5
        g2 = st['am_e2'] * 0.5
        T = st['am_T']
        psf_g1 = st['am_psf_e1'] * 0.5
        psf_g2 = st['am_psf_e2'] * 0.5
        psf_T = st['am_psf_T']
    else:
        g1 = st['g1_data']
        g2 = st['g2_data']
        T = st['T_data']
        psf_g1 = st['g1_model']
        psf_g2 = st['g2_model']
        psf_T = st['T_model']

    data = calc_rho_stats(
        ra=st['ra'],
        dec=st['dec'],
        g1=g1,
        g2=g2,
        T=T,
        psf_g1=psf_g1,
        psf_g2=psf_g2,
        psf_T=psf_T,
        min_sep=args.min_sep,
        max_sep=args.max_sep,
    )

    for key in data:
        fname = args.front + f'-{key}.fits'
        print(f'writing: {fname}')
        data[key].write(fname)


main()
